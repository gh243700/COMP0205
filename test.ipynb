{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "history_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gh243700/COMP0205/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIkxq5VvO8hL"
      },
      "outputs": [],
      "source": [
        "!pip install sounddevice"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y libportaudio2\n"
      ],
      "metadata": {
        "id": "YtOiWjMiP_GP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sounddevice"
      ],
      "metadata": {
        "id": "BaDocVChQWE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faster_whisper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HZBuG2DwQj0Y",
        "outputId": "a7d4c474-d13d-4f5f-e5fe-721205b389d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faster_whisper in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: ctranslate2<5,>=4.0 in /usr/local/lib/python3.11/dist-packages (from faster_whisper) (4.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster_whisper) (0.31.2)\n",
            "Requirement already satisfied: tokenizers<1,>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster_whisper) (0.21.1)\n",
            "Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.11/dist-packages (from faster_whisper) (1.22.0)\n",
            "Requirement already satisfied: av>=11 in /usr/local/lib/python3.11/dist-packages (from faster_whisper) (14.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from faster_whisper) (4.67.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster_whisper) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster_whisper) (2.0.2)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.11/dist-packages (from ctranslate2<5,>=4.0->faster_whisper) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster_whisper) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster_whisper) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster_whisper) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster_whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster_whisper) (4.13.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster_whisper) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster_whisper) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster_whisper) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime<2,>=1.14->faster_whisper) (1.13.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime<2,>=1.14->faster_whisper) (10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13->faster_whisper) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13->faster_whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13->faster_whisper) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.13->faster_whisper) (2025.4.26)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime<2,>=1.14->faster_whisper) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vosk"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVSwqJgvQte6",
        "outputId": "47a73f2c-9e0f-43d3-baad-705d3feb58b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vosk in /usr/local/lib/python3.11/dist-packages (0.3.45)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from vosk) (1.17.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from vosk) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from vosk) (4.67.1)\n",
            "Requirement already satisfied: srt in /usr/local/lib/python3.11/dist-packages (from vosk) (3.5.3)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.11/dist-packages (from vosk) (15.0.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->vosk) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->vosk) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->vosk) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->vosk) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->vosk) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deep_translator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rjpstx9ZQyQt",
        "outputId": "ce8c1015-d5b0-480e-d1bf-ec0566f59506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deep_translator in /usr/local/lib/python3.11/dist-packages (1.11.4)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.11/dist-packages (from deep_translator) (4.13.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from deep_translator) (2.32.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gtts"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOIQCijnQ2Do",
        "outputId": "bdfb785c-2f15-4f47-ed07-45d8c897197c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gtts in /usr/local/lib/python3.11/dist-packages (2.5.4)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from gtts) (2.32.3)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.11/dist-packages (from gtts) (8.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gtts) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip\n",
        "!unzip vosk-model-small-en-us-0.15.zip -d models/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3WjsbB7KUkzS",
        "outputId": "eebbe4d0-af54-485e-f0e0-04b7a3154887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-19 08:45:19--  https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip\n",
            "Resolving alphacephei.com (alphacephei.com)... 188.40.21.16, 2a01:4f8:13a:279f::2\n",
            "Connecting to alphacephei.com (alphacephei.com)|188.40.21.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 41205931 (39M) [application/zip]\n",
            "Saving to: ‘vosk-model-small-en-us-0.15.zip.1’\n",
            "\n",
            "vosk-model-small-en 100%[===================>]  39.30M  12.8MB/s    in 3.1s    \n",
            "\n",
            "2025-05-19 08:45:22 (12.8 MB/s) - ‘vosk-model-small-en-us-0.15.zip.1’ saved [41205931/41205931]\n",
            "\n",
            "Archive:  vosk-model-small-en-us-0.15.zip\n",
            "replace models/vosk-model-small-en-us-0.15/am/final.mdl? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ffmpeg-python"
      ],
      "metadata": {
        "id": "k7tJak4UVygv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "Ih8R0pUzXGRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y whisper"
      ],
      "metadata": {
        "id": "fCzEJq_AjkmG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf201249-9afb-4d6a-c379-e9bc8f02c3d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping whisper as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U openai-whisper"
      ],
      "metadata": {
        "id": "-gXFG_3Bt0FD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "from IPython.display import Javascript, display\n",
        "\n",
        "audio_queue = queue.Queue()\n",
        "def save_audio(b64_audio):\n",
        "    header, encoded = b64_audio.split(\",\", 1)\n",
        "    audio_data = base64.b64decode(encoded)\n",
        "    timestamp = int(time.time())\n",
        "    filename = f\"mic_chunk_{timestamp}.wav\"\n",
        "    with open(filename, \"wb\") as f:\n",
        "        f.write(audio_data)\n",
        "    print(f\"🎤 저장됨: {filename}\")\n",
        "    audio_queue.put(filename)\n",
        "\n",
        "def start_auto_recording():\n",
        "    # 1) register under simple name\n",
        "    output.register_callback(\"save_audio\", save_audio)\n",
        "\n",
        "    # 2) inject JS that calls that same name\n",
        "    auto_record_js = \"\"\"\n",
        "    if (!window.autoRecorderRunning) {\n",
        "      window.autoRecorderRunning = true;\n",
        "      const sleep = t => new Promise(r => setTimeout(r, t));\n",
        "      const toBase64 = blob => new Promise(r => {\n",
        "        const reader = new FileReader();\n",
        "        reader.onloadend = () => r(reader.result);\n",
        "        reader.readAsDataURL(blob);\n",
        "      });\n",
        "\n",
        "      navigator.mediaDevices.getUserMedia({audio:true})  // must be in-cell\n",
        "        .then(stream => {\n",
        "          (async () => {\n",
        "            while (true) {\n",
        "              const recorder = new MediaRecorder(stream);\n",
        "              const chunks = [];\n",
        "              recorder.ondataavailable = e => chunks.push(e.data);\n",
        "              recorder.start();\n",
        "              await sleep(3000);\n",
        "              recorder.stop();\n",
        "              await new Promise(res => recorder.onstop = res);\n",
        "              const blob = new Blob(chunks);\n",
        "              const b64 = await toBase64(blob);\n",
        "              google.colab.kernel.invokeFunction('save_audio', [b64], {});\n",
        "            }\n",
        "          })();\n",
        "        })\n",
        "        .catch(err => console.error(\"Mic permission error:\", err));\n",
        "    }\n",
        "    \"\"\"\n",
        "    display(Javascript(auto_record_js))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxd6riKVvqZz",
        "outputId": "14fce4eb-408c-48d0-d63f-2a8e351f474b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ No file in audio_queue after 5s—waiting again.\n",
            "⚠️ No file in audio_queue after 5s—waiting again.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import queue\n",
        "import sounddevice as sd\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "from faster_whisper import WhisperModel, BatchedInferencePipeline\n",
        "import string\n",
        "from vosk import Model, KaldiRecognizer\n",
        "from deep_translator import GoogleTranslator\n",
        "from gtts import gTTS\n",
        "import json\n",
        "import threading\n",
        "from threading import Thread\n",
        "import concurrent.futures\n",
        "import wave\n",
        "import whisper\n",
        "from IPython.display import Javascript, display\n",
        "from google.colab import output\n",
        "import base64\n",
        "import time\n",
        "\n",
        "# Settings\n",
        "TRIGGER_WORD = \"stop\"\n",
        "SAMPLE_RATE = 16000\n",
        "MODEL_PATH = \"models/vosk-model-small-en-us-0.15\"\n",
        "WHISPER_MODEL = \"turbo\"\n",
        "MODEL = WhisperModel(WHISPER_MODEL, device=\"cuda\", compute_type=\"int8\")\n",
        "batched_model = BatchedInferencePipeline(model=MODEL)\n",
        "\n",
        "q = queue.Queue()\n",
        "BUFFER_SIZE = 1024\n",
        "buffer = [('', 0, '', 0) for _ in range(BUFFER_SIZE)]  # (text, flag, lang, duration_time)\n",
        "b_index = 0\n",
        "b_ptr = 0\n",
        "lock = threading.Lock()\n",
        "result_queue = queue.Queue()\n",
        "\n",
        "\n",
        "\n",
        "def listen_for_trigger_and_save():\n",
        "    print(\"🎧 Listening... Speak and end with 'STOP'\")\n",
        "    model = whisper.load_model(\"base\")\n",
        "    audio_data = []\n",
        "    total_audio_data = []\n",
        "    num = 0\n",
        "    chunk_size = 8000\n",
        "\n",
        "    # wait for first valid WAV chunk\n",
        "    while True:\n",
        "        try:\n",
        "            file_path = audio_queue.get(timeout=5)\n",
        "        except queue.Empty:\n",
        "            print(\"⚠️ No file in audio_queue after 5s—waiting again.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"📥 수신된 오디오 파일: {file_path}\")\n",
        "        try:\n",
        "            wf = wave.open(file_path, \"rb\")\n",
        "            break\n",
        "        except wave.Error:\n",
        "            print(\"❌ 파일이 WAV 포맷이 아님. 무시합니다.\")\n",
        "\n",
        "    recognizer = KaldiRecognizer(model, wf.getframerate())\n",
        "    st = ''\n",
        "    while True:\n",
        "        data = wf.readframes(chunk_size)\n",
        "        if not data:\n",
        "            wf.close()\n",
        "            os.remove(file_path)\n",
        "            try:\n",
        "                file_path = audio_queue.get(timeout=5)\n",
        "            except queue.Empty:\n",
        "                print(\"⚠️ No file in audio_queue after 5s—waiting again.\")\n",
        "                continue\n",
        "            wf = wave.open(file_path, \"rb\")\n",
        "            continue\n",
        "\n",
        "        recognizer.AcceptWaveform(data)\n",
        "        result = json.loads(recognizer.PartialResult())\n",
        "        text = result.get(\"text\", \"\")\n",
        "\n",
        "        if text:\n",
        "            total_audio_data.append(data)\n",
        "            audio_data.append(data)\n",
        "            st += text\n",
        "\n",
        "            if TRIGGER_WORD in text.lower():\n",
        "                print(\"✅ Trigger word detected.\")\n",
        "                break\n",
        "\n",
        "            if st:\n",
        "                audio = np.concatenate(audio_data)\n",
        "                sf.write(f\"input{num}.wav\", audio, SAMPLE_RATE)\n",
        "                duration_seconds = len(audio) / SAMPLE_RATE\n",
        "                add_item(f\"input{num}.wav\", duration_seconds)\n",
        "                audio_data = []\n",
        "                st = ''\n",
        "                num += 1\n",
        "\n",
        "    full_audio = np.concatenate(total_audio_data)\n",
        "    sf.write(\"input.wav\", full_audio, SAMPLE_RATE)\n",
        "    duration_seconds = len(full_audio) / SAMPLE_RATE\n",
        "    print(f\"⏱️ Recording duration: {duration_seconds:.2f} seconds\")\n",
        "    result_queue.put((\"input.wav\", duration_seconds))\n",
        "\n",
        "def add_item(audio_path, duration_seconds):\n",
        "    global b_index\n",
        "    while buffer[b_index][1] != 0:\n",
        "        continue\n",
        "    buffer[b_index] = (audio_path, 1, '', duration_seconds)\n",
        "    b_index = (b_index + 1) % BUFFER_SIZE\n",
        "\n",
        "def translate_text(i):\n",
        "    global MODEL\n",
        "    audio_path, flag, lang, duration_seconds = buffer[i]\n",
        "    with lock:\n",
        "        segments, info = batched_model.transcribe(audio_path, beam_size=5, batch_size=16)\n",
        "\n",
        "    text = \"\"\n",
        "    for segment in segments:\n",
        "        text += segment.text\n",
        "\n",
        "    if any(char in text for char in \"가나다라마바사\"):\n",
        "        translated = GoogleTranslator(source='ko', target='en').translate(text)\n",
        "        lang = 'en'\n",
        "    else:\n",
        "        translated = GoogleTranslator(source='en', target='ko').translate(text)\n",
        "        lang = 'ko'\n",
        "\n",
        "    buffer[i] = (translated, 2, lang, duration_seconds)\n",
        "\n",
        "def transRoutine():\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
        "        i = 0\n",
        "        while True:\n",
        "            if buffer[i][1] == 1:\n",
        "                executor.submit(translate_text, i)\n",
        "                i = (i + 1) % BUFFER_SIZE\n",
        "\n",
        "def speak(text, lang):\n",
        "    tts = gTTS(text=text, lang=lang)\n",
        "    tts.save(\"output.mp3\")\n",
        "    os.system(\"afplay output.mp3\" if os.name == \"posix\" else \"start output.mp3\")\n",
        "\n",
        "def use_item_routine():\n",
        "    global b_ptr\n",
        "    while True:\n",
        "        if buffer[b_ptr][1] == 2:\n",
        "            text, flag, lang, duration_seconds = buffer[b_ptr]\n",
        "            print(f\"🔈 Speaking: {text}\")\n",
        "            speak(text, lang)\n",
        "            buffer[b_ptr] = ('', 0, '', 0)\n",
        "            b_ptr = (b_ptr + 1) % BUFFER_SIZE\n",
        "\n",
        "def main():\n",
        "    start_auto_recording()\n",
        "    producer_thread = Thread(target=listen_for_trigger_and_save)\n",
        "    translator_thread = Thread(target=transRoutine)\n",
        "    speaker_thread = Thread(target=use_item_routine)\n",
        "\n",
        "    producer_thread.start()\n",
        "    translator_thread.start()\n",
        "    speaker_thread.start()\n",
        "    #audio_path, duration = result_queue.get()\n",
        "    #print(f\"🎤 Audio saved: {audio_path}\")\n",
        "    #print(f\"⏱️ Total recording duration: {duration:.2f} seconds\")\n",
        "    producer_thread.join()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "Cfu_xITDO-5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mi71nMBWtn1f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}